# Seoul Bike Heat Map - Spark 제외 버전 (Airflow + MySQL + Kafka)

services:
  # ============================================
  # 데이터베이스 & 캐시
  # ============================================
  
  mysql:
    image: mysql:8.0
    container_name: seoul-bike-mysql
    restart: unless-stopped
    environment:
      MYSQL_ROOT_PASSWORD: cksgh970216!
      MYSQL_DATABASE: seoul_bike
      MYSQL_USER: hch16
      MYSQL_PASSWORD: cksgh970216!
      MYSQL_INNODB_BUFFER_POOL_SIZE: 128M
    ports:
      - "3306:3306"
    volumes:
      - mysql-data:/var/lib/mysql
      - ./scripts/init-mysql.sql:/docker-entrypoint-initdb.d/init.sql
    networks:
      - bike-network
    deploy:
      resources:
        limits:
          memory: 1G
        reservations:
          memory: 512M
    command: >
      --innodb-buffer-pool-size=128M
      --max-connections=50
      --innodb-log-buffer-size=8M
      --key-buffer-size=8M
      --tmp-table-size=16M
      --max-heap-table-size=16M
    healthcheck:
      test: ["CMD", "mysqladmin", "ping", "-h", "localhost", "-u", "root", "-pcksgh970216!"]
      interval: 10s
      timeout: 5s
      retries: 10
      start_period: 30s

  redis:
    image: redis:7-alpine
    container_name: seoul-bike-redis
    restart: unless-stopped
    ports:
      - "6379:6379"
    volumes:
      - redis-data:/data
    networks:
      - bike-network
    command: redis-server --appendonly yes --maxmemory 64mb --maxmemory-policy allkeys-lru
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 3s
      retries: 5

  # ============================================
  # Kafka & Zookeeper
  # ============================================
  
  zookeeper:
    image: confluentinc/cp-zookeeper:7.5.0
    container_name: seoul-bike-zookeeper
    restart: unless-stopped
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000
    ports:
      - "2181:2181"
    volumes:
      - zookeeper-data:/var/lib/zookeeper/data
    networks:
      - bike-network

  kafka:
    image: confluentinc/cp-kafka:7.5.0
    container_name: seoul-bike-kafka
    depends_on:
      - zookeeper
    restart: unless-stopped
    ports:
      - "9092:9092"
      - "29092:29092"
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:29092,PLAINTEXT_HOST://localhost:9092
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: "true"
    volumes:
      - kafka-data:/var/lib/kafka/data
    networks:
      - bike-network
    healthcheck:
      test: ["CMD", "kafka-topics", "--bootstrap-server", "localhost:9092", "--list"]
      interval: 30s
      timeout: 10s
      retries: 5

  kafka-ui:
    image: provectuslabs/kafka-ui:latest
    container_name: seoul-bike-kafka-ui
    restart: unless-stopped
    depends_on:
      - kafka
    ports:
      - "8080:8080"
    environment:
      KAFKA_CLUSTERS_0_NAME: seoul-bike-cluster
      KAFKA_CLUSTERS_0_BOOTSTRAPSERVERS: kafka:29092
      KAFKA_CLUSTERS_0_ZOOKEEPER: zookeeper:2181
    networks:
      - bike-network

  # ============================================
  # Airflow (워크플로우 오케스트레이션)
  # ============================================
  
  airflow-postgres:
    image: postgres:15-alpine
    container_name: seoul-bike-airflow-postgres
    restart: unless-stopped
    environment:
      POSTGRES_USER: airflow
      POSTGRES_PASSWORD: airflow
      POSTGRES_DB: airflow
    volumes:
      - airflow-postgres-data:/var/lib/postgresql/data
    networks:
      - bike-network
    healthcheck:
      test: ["CMD", "pg_isready", "-U", "airflow"]
      interval: 10s
      timeout: 5s
      retries: 5

  airflow-init:
    image: apache/airflow:2.8.0
    container_name: seoul-bike-airflow-init
    depends_on:
      - airflow-postgres
    environment:
      AIRFLOW__CORE__EXECUTOR: LocalExecutor
      AIRFLOW__DATABASE__SQL_ALCHEMY_CONN: postgresql+psycopg2://airflow:airflow@airflow-postgres/airflow
      AIRFLOW__CORE__FERNET_KEY: ''
      AIRFLOW__CORE__DAGS_ARE_PAUSED_AT_CREATION: 'true'
      AIRFLOW__CORE__LOAD_EXAMPLES: 'false'
      _AIRFLOW_DB_MIGRATE: 'true'
      _AIRFLOW_WWW_USER_CREATE: 'true'
      _AIRFLOW_WWW_USER_USERNAME: airflow
      _AIRFLOW_WWW_USER_PASSWORD: airflow
    volumes:
      - ./airflow/dags:/opt/airflow/dags
      - ./airflow/logs:/opt/airflow/logs
      - ./airflow/plugins:/opt/airflow/plugins
    networks:
      - bike-network
    command: version

  airflow-webserver:
    image: apache/airflow:2.8.0
    container_name: seoul-bike-airflow-webserver
    restart: unless-stopped
    depends_on:
      airflow-init:
        condition: service_completed_successfully
      mysql:
        condition: service_healthy
      kafka:
        condition: service_healthy
    environment:
      AIRFLOW__CORE__EXECUTOR: LocalExecutor
      AIRFLOW__DATABASE__SQL_ALCHEMY_CONN: postgresql+psycopg2://airflow:airflow@airflow-postgres/airflow
      AIRFLOW__CORE__FERNET_KEY: ''
      AIRFLOW__CORE__DAGS_ARE_PAUSED_AT_CREATION: 'true'
      AIRFLOW__CORE__LOAD_EXAMPLES: 'false'
      AIRFLOW__WEBSERVER__EXPOSE_CONFIG: 'true'
      SEOUL_API_KEY: ${SEOUL_API_KEY}
      MYSQL_HOST: mysql
      MYSQL_DATABASE: seoul_bike
      MYSQL_USER: hch16
      MYSQL_PASSWORD: cksgh970216!
      KAFKA_BOOTSTRAP_SERVERS: kafka:29092
    volumes:
      - ./airflow/dags:/opt/airflow/dags
      - ./airflow/logs:/opt/airflow/logs
      - ./airflow/plugins:/opt/airflow/plugins
    ports:
      - "8082:8080"
    networks:
      - bike-network
    command: webserver
    healthcheck:
      test: ["CMD-SHELL", "python -c \"import urllib.request; urllib.request.urlopen('http://localhost:8080/health')\""]
      interval: 30s
      timeout: 10s
      retries: 10
      start_period: 60s

  airflow-scheduler:
    image: apache/airflow:2.8.0
    container_name: seoul-bike-airflow-scheduler
    restart: unless-stopped
    depends_on:
      airflow-init:
        condition: service_completed_successfully
      mysql:
        condition: service_healthy
      kafka:
        condition: service_healthy
    environment:
      AIRFLOW__CORE__EXECUTOR: LocalExecutor
      AIRFLOW__DATABASE__SQL_ALCHEMY_CONN: postgresql+psycopg2://airflow:airflow@airflow-postgres/airflow
      AIRFLOW__CORE__FERNET_KEY: ''
      AIRFLOW__CORE__DAGS_ARE_PAUSED_AT_CREATION: 'true'
      AIRFLOW__CORE__LOAD_EXAMPLES: 'false'
      SEOUL_API_KEY: ${SEOUL_API_KEY}
      MYSQL_HOST: mysql
      MYSQL_DATABASE: seoul_bike
      MYSQL_USER: hch16
      MYSQL_PASSWORD: cksgh970216!
      KAFKA_BOOTSTRAP_SERVERS: kafka:29092
    volumes:
      - ./airflow/dags:/opt/airflow/dags
      - ./airflow/logs:/opt/airflow/logs
      - ./airflow/plugins:/opt/airflow/plugins
    networks:
      - bike-network
    command: scheduler

  # ============================================
  # FastAPI (웹 애플리케이션)
  # ============================================
  
  fastapi:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: seoul-bike-fastapi
    depends_on:
      mysql:
        condition: service_healthy
      redis:
        condition: service_healthy
    environment:
      # 서버 설정
      HOST: "0.0.0.0"
      PORT: "8000"
      DEBUG: "true"
      RELOAD: "false"
      # MySQL 설정 (Docker 네트워크 내부 호스트명 사용)
      MYSQL_HOST: mysql
      MYSQL_PORT: "3306"
      MYSQL_DATABASE: seoul_bike
      MYSQL_USER: hch16
      MYSQL_PASSWORD: cksgh970216!
      # Redis 설정
      REDIS_HOST: redis
      REDIS_PORT: "6379"
      # Kafka 설정
      KAFKA_BOOTSTRAP_SERVERS: kafka:29092
      # 서울 API 키
      SEOUL_API_KEY: ${SEOUL_API_KEY:-}
    ports:
      - "8000:8000"
    volumes:
      - ./app:/app/app:ro
      - ./pipeline:/app/pipeline:ro
    networks:
      - bike-network
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 30s

networks:
  bike-network:
    driver: bridge

volumes:
  mysql-data:
  redis-data:
  zookeeper-data:
  kafka-data:
  airflow-postgres-data:
