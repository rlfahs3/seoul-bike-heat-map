"""
Seoul Bike Heat Map - ETL DAG
ì„œìš¸ì‹œ ë”°ë¦‰ì´ ì‹¤ì‹œê°„ ì •ë³´ë¥¼ ìˆ˜ì§‘í•˜ì—¬ MySQLì— ì €ì¥í•˜ê³  í†µê³„ë¥¼ ê³„ì‚°í•˜ëŠ” DAG

ì‹¤í–‰ ì£¼ê¸°: 30ë¶„ë§ˆë‹¤
"""
from airflow import DAG
from airflow.operators.python import PythonOperator
from airflow.providers.mysql.operators.mysql import MySqlOperator
from airflow.providers.mysql.hooks.mysql import MySqlHook
from datetime import datetime, timedelta
from typing import List, Dict
import logging
import os

# ë¡œì»¬ ëª¨ë“ˆ import
from utils.seoul_api import fetch_bike_data
from utils.data_processor import clean_station_data

logger = logging.getLogger(__name__)

# ============================================
# DAG ê¸°ë³¸ ì„¤ì •
# ============================================

default_args = {
    'owner': 'seoul-bike',
    'depends_on_past': False,
    'email_on_failure': False,
    'email_on_retry': False,
    'retries': 3,
    'retry_delay': timedelta(minutes=2),
    'execution_timeout': timedelta(minutes=10),
}

dag = DAG(
    dag_id='seoul_bike_etl',
    default_args=default_args,
    description='ì„œìš¸ ë”°ë¦‰ì´ ë°ì´í„° ìˆ˜ì§‘ ë° ì²˜ë¦¬',
    schedule_interval='*/30 * * * *',  # 30ë¶„ë§ˆë‹¤
    start_date=datetime(2024, 1, 1),
    catchup=False,
    tags=['seoul', 'bike', 'etl', 'heatmap'],
    max_active_runs=1,
    concurrency=2,
)

# ============================================
# Task í•¨ìˆ˜ ì •ì˜
# ============================================

def task_fetch_bike_data(**context):
    """
    Task 1: ì„œìš¸ì‹œ APIì—ì„œ ë”°ë¦‰ì´ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
    """
    api_key = os.getenv("SEOUL_API_KEY")
    
    if not api_key:
        raise ValueError("SEOUL_API_KEY environment variable not set")
    
    logger.info("Fetching bike data from Seoul API...")
    raw_data = fetch_bike_data(api_key)
    
    if not raw_data:
        raise ValueError("No data fetched from API")
    
    logger.info(f"Fetched {len(raw_data)} stations")
    
    # XComì— ë°ì´í„° ì €ì¥ (ë‹¤ìŒ Taskë¡œ ì „ë‹¬)
    context['task_instance'].xcom_push(key='raw_bike_data', value=raw_data)
    
    return len(raw_data)


def task_process_bike_data(**context):
    """
    Task 2: ë°ì´í„° ì „ì²˜ë¦¬ ë° ê²€ì¦
    """
    # ì´ì „ Taskì—ì„œ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
    task_instance = context['task_instance']
    raw_data = task_instance.xcom_pull(task_ids='fetch_bike_data', key='raw_bike_data')
    
    if not raw_data:
        raise ValueError("No raw data received from previous task")
    
    logger.info(f"Processing {len(raw_data)} stations...")
    stations, status_history = clean_station_data(raw_data)
    
    logger.info(f"Processed: {len(stations)} stations, {len(status_history)} status records")
    
    # ë‹¤ìŒ Taskë¡œ ì „ë‹¬
    task_instance.xcom_push(key='stations', value=stations)
    task_instance.xcom_push(key='status_history', value=status_history)
    
    return {
        'station_count': len(stations),
        'history_count': len(status_history)
    }


def task_save_to_mysql(**context):
    """
    Task 3: MySQLì— ë°ì´í„° ì €ì¥
    - bike_stations: UPSERT (INSERT ... ON DUPLICATE KEY UPDATE)
    - bike_status_history: INSERT
    """
    task_instance = context['task_instance']
    stations = task_instance.xcom_pull(task_ids='process_bike_data', key='stations')
    status_history = task_instance.xcom_pull(task_ids='process_bike_data', key='status_history')
    
    if not stations or not status_history:
        raise ValueError("No processed data received")
    
    # MySQL Hook ìƒì„±
    mysql_hook = MySqlHook(mysql_conn_id='mysql_default')
    
    # ===== 1. bike_stations í…Œì´ë¸” UPSERT =====
    logger.info(f"Upserting {len(stations)} stations...")
    
    station_sql = """
        INSERT INTO bike_stations (station_id, station_name, latitude, longitude, rack_total_count)
        VALUES (%s, %s, %s, %s, %s)
        ON DUPLICATE KEY UPDATE
            station_name = VALUES(station_name),
            latitude = VALUES(latitude),
            longitude = VALUES(longitude),
            rack_total_count = VALUES(rack_total_count),
            updated_at = CURRENT_TIMESTAMP
    """
    
    # executemanyë¡œ ë°°ì¹˜ ì‹¤í–‰
    conn = mysql_hook.get_conn()
    cursor = conn.cursor()
    
    station_rows = [(
        s['station_id'],
        s['station_name'],
        s['latitude'],
        s['longitude'],
        s['rack_total_count']
    ) for s in stations]
    
    cursor.executemany(station_sql, station_rows)
    conn.commit()
    cursor.close()
    
    logger.info(f"Stations upserted: {len(stations)}")
    
    # ===== 2. bike_status_history í…Œì´ë¸” INSERT =====
    logger.info(f"Inserting {len(status_history)} status records...")
    
    history_sql = """
        INSERT INTO bike_status_history 
        (station_id, parking_bike_count, rack_total_count, recorded_at)
        VALUES (%s, %s, %s, %s)
    """
    
    history_rows = [(
        h['station_id'],
        h['parking_bike_count'],
        h['rack_total_count'],
        h['recorded_at']
    ) for h in status_history]
    
    cursor = conn.cursor()
    cursor.executemany(history_sql, history_rows)
    conn.commit()
    cursor.close()
    conn.close()
    
    logger.info(f"Status history inserted: {len(status_history)}")
    
    return {
        'stations_saved': len(stations),
        'history_saved': len(status_history)
    }


def task_calculate_stats(**context):
    """
    Task 4: íˆíŠ¸ë§µìš© í†µê³„ ê³„ì‚° (ì¦ë¶„ ì—…ë°ì´íŠ¸)
    - í˜„ì¬ ì‹œê°„ëŒ€(hour)ì™€ ìš”ì¼(day_of_week)ì— ëŒ€í•´ì„œë§Œ í†µê³„ ì—…ë°ì´íŠ¸
    - ë§¤ë²ˆ ì „ì²´ ë°ì´í„°ë¥¼ ìŠ¤ìº”í•˜ì§€ ì•Šê³ , ìµœê·¼ 1ì‹œê°„ ë°ì´í„°ë§Œ ì²˜ë¦¬
    """
    mysql_hook = MySqlHook(mysql_conn_id='mysql_default')
    
    logger.info("Calculating availability statistics...")
    
    # í˜„ì¬ ì‹œê°„ëŒ€ì™€ ìš”ì¼ í™•ì¸
    time_info = mysql_hook.get_first("""
        SELECT HOUR(NOW()) as current_hour, WEEKDAY(NOW()) as current_dow
    """)
    current_hour = time_info[0]
    current_dow = time_info[1]
    
    logger.info(f"Updating stats for hour={current_hour}, day_of_week={current_dow}")
    
    # ì¦ë¶„ ì—…ë°ì´íŠ¸: í˜„ì¬ ì‹œê°„ëŒ€ + ìš”ì¼ì— ëŒ€í•´ì„œë§Œ 7ì¼ì¹˜ ë°ì´í„°ë¡œ í†µê³„ ê³„ì‚°
    sql = """
        INSERT INTO bike_availability_stats (
            station_id,
            hour_of_day,
            day_of_week,
            avg_availability,
            avg_parking_count,
            sample_count
        )
        SELECT 
            station_id,
            HOUR(recorded_at) as hour_of_day,
            WEEKDAY(recorded_at) as day_of_week,
            GREATEST(AVG(availability_rate), 0) as avg_availability,
            AVG(parking_bike_count) as avg_parking_count,
            COUNT(*) as sample_count
        FROM bike_status_history
        WHERE recorded_at >= DATE_SUB(NOW(), INTERVAL 7 DAY)
          AND HOUR(recorded_at) = %s
          AND WEEKDAY(recorded_at) = %s
        GROUP BY station_id, HOUR(recorded_at), WEEKDAY(recorded_at)
        ON DUPLICATE KEY UPDATE
            avg_availability = VALUES(avg_availability),
            avg_parking_count = VALUES(avg_parking_count),
            sample_count = VALUES(sample_count),
            last_updated = CURRENT_TIMESTAMP
    """
    
    mysql_hook.run(sql, parameters=(current_hour, current_dow))
    
    # ì—…ë°ì´íŠ¸ëœ ë ˆì½”ë“œ ìˆ˜ í™•ì¸
    affected = mysql_hook.get_first("""
        SELECT COUNT(*) FROM bike_availability_stats 
        WHERE hour_of_day = %s AND day_of_week = %s
    """, parameters=(current_hour, current_dow))
    updated_count = affected[0] if affected else 0
    
    logger.info(f"Statistics updated: {updated_count} records for hour={current_hour}, dow={current_dow}")
    
    # ì „ì²´ í†µê³„ ê°œìˆ˜ë„ í™•ì¸
    total = mysql_hook.get_first("SELECT COUNT(*) FROM bike_availability_stats")
    total_count = total[0] if total else 0
    
    logger.info(f"Total stats records: {total_count}")
    
    return {
        'updated_count': updated_count,
        'total_count': total_count,
        'hour': current_hour,
        'day_of_week': current_dow
    }


def task_cleanup_old_data(**context):
    """
    Task 5: ì˜¤ë˜ëœ ë°ì´í„° ì •ë¦¬
    - 7ì¼(1ì£¼) ì´ìƒ ëœ bike_status_history ë°ì´í„° ì‚­ì œ
    - í†µê³„(bike_availability_stats)ëŠ” ìœ ì§€
    """
    mysql_hook = MySqlHook(mysql_conn_id='mysql_default')
    
    # ì‚­ì œ ì „ ì¹´ìš´íŠ¸
    before_count = mysql_hook.get_first(
        "SELECT COUNT(*) FROM bike_status_history WHERE recorded_at < DATE_SUB(NOW(), INTERVAL 7 DAY)"
    )
    rows_to_delete = before_count[0] if before_count else 0
    
    if rows_to_delete > 0:
        logger.info(f"ğŸ—‘ï¸ Cleaning up {rows_to_delete} old records (older than 7 days/1 week)...")
        
        # 7ì¼(1ì£¼) ì´ìƒ ëœ ë°ì´í„° ì‚­ì œ
        mysql_hook.run("""
            DELETE FROM bike_status_history 
            WHERE recorded_at < DATE_SUB(NOW(), INTERVAL 7 DAY)
        """)
        
        logger.info(f"âœ… Deleted {rows_to_delete} old records")
    else:
        logger.info("ğŸ“­ No old records to clean up")
    
    # í˜„ì¬ í…Œì´ë¸” ìƒíƒœ
    current_count = mysql_hook.get_first("SELECT COUNT(*) FROM bike_status_history")
    
    return {
        'deleted_count': rows_to_delete,
        'remaining_count': current_count[0] if current_count else 0
    }


# ============================================
# Task ì •ì˜
# ============================================

fetch_task = PythonOperator(
    task_id='fetch_bike_data',
    python_callable=task_fetch_bike_data,
    provide_context=True,
    dag=dag,
)

process_task = PythonOperator(
    task_id='process_bike_data',
    python_callable=task_process_bike_data,
    provide_context=True,
    dag=dag,
)

save_task = PythonOperator(
    task_id='save_to_mysql',
    python_callable=task_save_to_mysql,
    provide_context=True,
    dag=dag,
)

stats_task = PythonOperator(
    task_id='calculate_stats',
    python_callable=task_calculate_stats,
    provide_context=True,
    dag=dag,
)

cleanup_task = PythonOperator(
    task_id='cleanup_old_data',
    python_callable=task_cleanup_old_data,
    provide_context=True,
    dag=dag,
)

fetch_task >> process_task >> save_task >> stats_task >> cleanup_task